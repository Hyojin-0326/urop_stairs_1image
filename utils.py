import numpy as np
import cv2
import pyrealsense2 as rs
from scipy.spatial import KDTree
from sklearn.neighbors import NearestNeighbors
import torch
import stairs
import os
import open3d as o3d
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D




class Config:
    fx, fy, cx, cy = 605.9815, 606.1337, 308.5001, 246.4238
    intrinsic_matrix = intrinsic_matrix = np.array([
    [fx,  0, cx],  # ì´ˆì  ê±°ë¦¬ fx, ì£¼ì (cx)
    [ 0, fy, cy],  # ì´ˆì  ê±°ë¦¬ fy, ì£¼ì (cy)
    [ 0,  0,  1]   # ë³€í™˜ì„ ìœ„í•œ ë§ˆì§€ë§‰ í–‰ (ê³ ì •)
    
])
    intrinsics = 605.9815, 606.1337, 308.5001, 246.4238
    depth_scale = 1000
    k = 10
    threshold = 0.9
    voxel_size = 50 #mmë‹¨ìœ„ì´ë¯€ë¡œ 5cmì„

class Point:
    def __init__(self, position, normal=None, isGround=False):
        self.position = position # 3d ì¢Œí‘œ
        self.normal = normal # ë²•ë²¡í„°
        self.isGround = isGround 

class VoxelGrid:
    def __init__(self, points, voxel_size):
        self.voxel_size = voxel_size
        self.points = points # ê° ì ì˜ x, y ,z ì¢Œí‘œë¥¼ ì €ì¥í•¨. points[i] = [x, y ,z]
        self.voxel_grid = {}
        for i, pt in enumerate(points): #  í¬ì¸íŠ¸ë“¤ì„ voxelgridì— í• ë‹¹í•¨
            voxel_key = tuple(np.floor(pt.position / voxel_size).astype(int))
            if voxel_key not in self.voxel_grid:
                self.voxel_grid[voxel_key] = []
            self.voxel_grid[voxel_key].append(i)
        
        # Building a k-d tree for fast k-NN search
        self.tree = NearestNeighbors(n_neighbors=Config.k, algorithm='kd_tree')
        point_positions = np.array([pt.position for pt in points])  # assuming pt.position is a 3D vector
        self.tree.fit(point_positions)

    def getKNN(self, position, k, search_radius, points):
        # Use the k-d tree to find k nearest neighbors within the search radius
        distances, indices = self.tree.radius_neighbors([position], radius=search_radius)
        
        # Filter out the neighbors that are beyond the search radius
        neighbors = [idx for idx in indices[0] if np.linalg.norm(points[idx].position - position) <= search_radius]
        
        return neighbors[:k]  # return the first k neighbors

def detect_horizontal_edges_and_save(image_path, output_path):
    # RGB ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    img = cv2.imread(image_path)

    if img is None:
        print(f"Error: Failed to load image at {image_path}")
        return
    

    # ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # ì—£ì§€ ê²€ì¶œ: Canny Edge Detection ì‚¬ìš©
    edges = cv2.Canny(gray, 100, 200)

    # ìˆ˜í‰ ì—£ì§€ ì°¾ê¸° ìœ„í•œ ì»¤ë„ ì •ì˜
    kernel = np.ones((1, 10), np.uint8)  # ìˆ˜í‰ ë°©í–¥ìœ¼ë¡œ ìŠ¤íŠ¸ë¡œí¬ë¥¼ ë„“í˜
    horizontal_edges = cv2.dilate(edges, kernel, iterations=1)

    # ìˆ˜í‰ ì—£ì§€ì— ì„  ê·¸ë¦¬ê¸°
    lines = cv2.HoughLinesP(horizontal_edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)  # ë¹¨ê°„ìƒ‰ ì„  ê·¸ë¦¬ê¸°

    # ì´ë¯¸ì§€ ì €ì¥
    cv2.imwrite(output_path, img)
    print(f"Image saved at {output_path}")



def preprocessPointCloud(points, voxel_size=Config.voxel_size, k=Config.k, threshold=Config.threshold):
    grid = VoxelGrid(points, voxel_size)
    search_radius = voxel_size * 1.5

    # Using the bottom 80% of the point cloud
    min_y = np.min([pt.position[1] for pt in points])
    max_y = np.max([pt.position[1] for pt in points])
    bottom_80_percent = min_y + (max_y - min_y) * 0.2  # 20% ì§€ì ë¶€í„° í•˜ë‹¨ 80%

    points_bottom_80 = [pt for pt in points if pt.position[1] <= bottom_80_percent]

    for pt in points_bottom_80:
        neighbors = grid.getKNN(pt.position, k, search_radius, points)
        
        if len(neighbors) < k:
            pt.isGround = False
            continue
        
        # Compute covariance matrix
        mean = np.mean([points[idx].position for idx in neighbors], axis=0)
        covariance = np.cov([points[idx].position - mean for idx in neighbors], rowvar=False)

        # Eigen decomposition
        eigvals, eigvecs = np.linalg.eigh(covariance)
        normal = eigvecs[:, np.argmin(eigvals)]  # Smallest eigenvalue corresponds to normal

        if normal[2] < 0:
            normal = -normal
        pt.normal = normal
        pt.isGround = np.dot(normal, np.array([0, 0, 1])) > threshold

    # Remove ground points
    points_without_ground = [pt for pt in points if not pt.isGround] # point ê°ì²´
    ground_points = [pt for pt in points if pt.isGround]
    return points_without_ground, ground_points

def preprocess_RGBimg(rgb_image, points, ground_points, intrinsics = Config.intrinsics):
    """
    RGB ì´ë¯¸ì§€ì—ì„œ ê·¸ë¼ìš´ë“œ í”Œë ˆì¸ì— í•´ë‹¹í•˜ëŠ” í¬ì¸íŠ¸ë¥¼ ë‚ ë¦¬ëŠ” í•¨ìˆ˜.
    
    :param rgb_image: ì›ë³¸ RGB ì´ë¯¸ì§€
    :param points: ì „ì²´ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
    :param ground_points: ê·¸ë¼ìš´ë“œë¡œ íŒë‹¨ëœ í¬ì¸íŠ¸ë“¤ì˜ ì¸ë±ìŠ¤
    :param intrinsics: ì¹´ë©”ë¼ ë‚´ì¬ íŒŒë¼ë¯¸í„° (fx, fy, cx, cy)
    :return: ê·¸ë¼ìš´ë“œ í”Œë ˆì¸ì´ ì œê±°ëœ RGB ì´ë¯¸ì§€
    """
    # ë§Œì•½ pointsê°€ ë¦¬ìŠ¤íŠ¸ë¼ë©´ numpy ë°°ì—´ë¡œ ë³€í™˜
    points = np.array([pt.position for pt in points]) if isinstance(points, list) else points

    # 3D í¬ì¸íŠ¸ë¥¼ 2D ì´ë¯¸ì§€ë¡œ íˆ¬ì˜
    ground_3d_points = points[ground_points]  # ground_pointsëŠ” ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨
    ground_2d_points = project_to_2d(ground_3d_points, intrinsics)

    # 2D ì¢Œí‘œë¥¼ ì´ë¯¸ì§€ í¬ê¸° ë‚´ì—ì„œ ìœ íš¨í•œ ê°’ìœ¼ë¡œ í´ë¦¬í•‘
    h, w, _ = rgb_image.shape
    u, v = ground_2d_points[:, 0], ground_2d_points[:, 1]
    u = np.clip(u.astype(int), 0, w - 1)
    v = np.clip(v.astype(int), 0, h - 1)

    # ê·¸ë¼ìš´ë“œ í¬ì¸íŠ¸ì— í•´ë‹¹í•˜ëŠ” í”½ì…€ì„ ë§ˆìŠ¤í¬ë¡œ ì„¤ì •
    mask = np.zeros((h, w), dtype=np.uint8)
    mask[v, u] = 1

    # ê·¸ë¼ìš´ë“œ ì˜ì—­ì„ ì œê±°í•˜ê±°ë‚˜ ëŒ€ì²´ (ì˜ˆ: 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹)
    rgb_image[mask == 1] = 0  # ê·¸ë¼ìš´ë“œ ë¶€ë¶„ì„ ê²€ì •ìƒ‰ìœ¼ë¡œ ëŒ€ì²´

    return rgb_image



def depth_to_pointcloud(depth_map, intrinsic_matrix = Config.intrinsic_matrix, depth_scale=Config.depth_scale):

    fx = intrinsic_matrix[0, 0]
    fy = intrinsic_matrix[1, 1]
    cx = intrinsic_matrix[0, 2]
    cy = intrinsic_matrix[1, 2]
    
    height, width = depth_map.shape
    points = []
    
    # ê° í”½ì…€ì— ëŒ€í•´ 3D ì¢Œí‘œ ê³„ì‚°
    for v in range(height):
        for u in range(width):
            depth_val = depth_map[v, u] / depth_scale  # mmë¥¼ meterë¡œ ë³€í™˜
            
            if depth_val == 0:  # ê¹Šì´ ê°’ì´ 0ì¸ ê²½ìš°ëŠ” ê±´ë„ˆë›°ê¸°
                continue
            
            # 2D ì¢Œí‘œ (u, v)ë¥¼ 3D ì¢Œí‘œ (X, Y, Z)ë¡œ ë³€í™˜
            X = (u - cx) * depth_val / fx
            Y = (v - cy) * depth_val / fy
            Z = depth_val
            
            # Point ê°ì²´ ìƒì„±
            pt = Point(position=np.array([X, Y, Z]))
            points.append(pt)
            print(f"Pixel ({u}, {v}): Depth: {depth_val}, X: {X}, Y: {Y}, Z: {Z}")

    
    return points


def project_to_2d(points, depth_scale = Config.depth_scale,intrinsics=Config.intrinsics): 
    """
    3D í¬ì¸íŠ¸ë¥¼ 2D RGB ì´ë¯¸ì§€ë¡œ íˆ¬ì˜í•˜ëŠ” í•¨ìˆ˜.
    
    :param points: 3D í¬ì¸íŠ¸ (N x 3) numpy ë°°ì—´
    :param intrinsics: ì¹´ë©”ë¼ì˜ ë‚´ì¬ íŒŒë¼ë¯¸í„° (fx, fy, cx, cy)
    :return: 2D ì´ë¯¸ì§€ ì¢Œí‘œ (u, v)
    """
    fx, fy, cx, cy = intrinsics
    u = (points[:, 0] * fx / points[:, 2]) + cx
    v = (points[:, 1] * fy / points[:, 2]) + cy
    return np.column_stack((u, v))


def pointcloud_visualization(points, filename="pointcloud.png"):
    # í¬ì¸íŠ¸ë“¤ì˜ x, y, z ì¢Œí‘œ ì¶”ì¶œ
    x_coords = [pt.position[0] for pt in points]
    y_coords = [pt.position[1] for pt in points]
    z_coords = [pt.position[2] for pt in points]

    # 3D í”Œë¡¯ ìƒì„±
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')

    # í¬ì¸íŠ¸ë“¤ì„ ì ìœ¼ë¡œ í”Œë¡œíŒ…
    ax.scatter(x_coords, y_coords, z_coords, c='b', marker='o', s=1)  # íŒŒë€ìƒ‰ ì , í¬ê¸° 1

    # ì¶• ë¼ë²¨
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')

    # ê·¸ë˜í”„ ì œëª©
    ax.set_title('Point Cloud Visualization')

    # ê·¸ë˜í”„ ì´ë¯¸ì§€ ì €ì¥ (PNG ë˜ëŠ” JPG)
    plt.savefig(filename, dpi=300)
    plt.close()  # ê·¸ë˜í”„ ë‹«ê¸°



#----------------- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_rgb_from_bin(bin_path, frame_idx, height=480, width=640):
    data_path = os.path.dirname(os.path.abspath(__file__))
    meta_path = os.path.join(data_path, "data", "meta.txt")

    # ğŸ”¹ 1) meta.txtì—ì„œ í”„ë ˆì„ ê°œìˆ˜ ì½ê¸°
    try:
        with open(meta_path, "r") as f:
            total_frames = int(f.readline().strip())  # ì²« ë²ˆì§¸ ì¤„ì— ì €ì¥ëœ í”„ë ˆì„ ê°œìˆ˜ ì½ê¸°
    except FileNotFoundError:
        raise FileNotFoundError(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ {meta_path}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    except ValueError:
        raise ValueError(f"âŒ {meta_path}ì—ì„œ í”„ë ˆì„ ê°œìˆ˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

    # ğŸ”¹ 2) frame_idxê°€ ìœ íš¨í•œì§€ í™•ì¸
    if frame_idx >= total_frames or frame_idx < 0:
        raise ValueError(f"âš ï¸ frame_idx {frame_idx}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤! (ì´ {total_frames}ê°œ í”„ë ˆì„)")

    # ğŸ”¹ 3) .bin íŒŒì¼ì—ì„œ RGB ë°ì´í„° ë¡œë“œ
    try:
        rgb_data = np.fromfile(bin_path, dtype=np.uint8)

        # ì „ì²´ ë°ì´í„°ê°€ (total_frames, H, W, 3) í¬ê¸°ì¸ì§€ í™•ì¸
        expected_size = total_frames * height * width * 3
        if len(rgb_data) != expected_size:
            raise ValueError(f"âŒ RGB ë°ì´í„° í¬ê¸° ë¶ˆì¼ì¹˜! ì˜ˆìƒ {expected_size}, ì‹¤ì œ {len(rgb_data)}")

        # ğŸ”¹ 4) (í”„ë ˆì„ ê°œìˆ˜, H, W, 3) í˜•íƒœë¡œ reshape
        rgb_data = rgb_data.reshape((total_frames, height, width, 3))

        # ğŸ”¹ 5) frame_idxì— í•´ë‹¹í•˜ëŠ” í”„ë ˆì„ ë°˜í™˜
        rgb_image = rgb_data[frame_idx]

    except Exception as e:
        raise RuntimeError(f"âŒ RGB .bin íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return rgb_image



def align_depth_to_rgb(depth_bin_path, rgb_bin_path, frame_idx, height=480, width=640):
    context = rs.context()
    devices = context.query_devices()
    data_path = os.path.dirname(os.path.abspath(__file__))
    meta_path = os.path.join(data_path, "data", "meta.txt")
    try:
        with open(meta_path, "r") as f:
            total_frames = int(f.readline().strip())  # ì²« ì¤„ì—ì„œ í”„ë ˆì„ ê°œìˆ˜ ì½ê¸°
        print(f"ğŸ”¹ meta.txtì—ì„œ ì½ì€ í”„ë ˆì„ ê°œìˆ˜: {total_frames}")
    except FileNotFoundError:
        raise FileNotFoundError(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ {meta_path}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    except ValueError:
        raise ValueError(f"âŒ {meta_path}ì—ì„œ í”„ë ˆì„ ê°œìˆ˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

    if len(devices) == 0:
        print("ğŸ”¹ No device connected, using default intrinsics & loading from .bin files")
        intrinsics = rs.intrinsics()
        intrinsics.width = width
        intrinsics.height = height
        intrinsics.ppx = 308.5001  # ê¸°ë³¸ ê´‘í•™ ì¤‘ì‹¬ X (cx)
        intrinsics.ppy = 246.4238  # ê¸°ë³¸ ê´‘í•™ ì¤‘ì‹¬ Y (cy)
        intrinsics.fx = 605.9815  # ê¸°ë³¸ ì´ˆì  ê±°ë¦¬ X (fx)
        intrinsics.fy = 606.1337  # ê¸°ë³¸ ì´ˆì  ê±°ë¦¬ Y (fy)
        intrinsics.model = rs.distortion.none  # ì™œê³¡ ì—†ìŒ
        intrinsics.coeffs = [0, 0, 0, 0, 0]  
        
        # --- .bin íŒŒì¼ì—ì„œ RGB & Depth ë¶ˆëŸ¬ì˜¤ê¸° ---
        depth_map = np.fromfile(depth_bin_path, dtype=np.float32)
        depth_map = depth_map.reshape((total_frames, height, width))
        depth_map = depth_map[frame_idx]

        rgb_image = load_rgb_from_bin(rgb_bin_path, frame_idx)

        if frame_idx >= total_frames:
            raise ValueError(f"âš ï¸ frame_idx {frame_idx}ê°€ ì €ì¥ëœ í”„ë ˆì„ ê°œìˆ˜ {total_frames}ë³´ë‹¤ í¼")

    else:
        try:
            print("âœ… Realsense device detected, capturing frames...")
            pipeline = rs.pipeline()
            config = rs.config()
            config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
            config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
            profile = pipeline.start(config)

            # ì¹´ë©”ë¼ Intrinsics ê°€ì ¸ì˜¤ê¸°
            color_profile = profile.get_stream(rs.stream.color)
            intr = color_profile.as_video_stream_profile().get_intrinsics()
            fx, fy, cx, cy = intr.fx, intr.fy, intr.ppx, intr.ppy

            # Depth â†’ RGB ì •ë ¬ ìˆ˜í–‰
            align_to = rs.stream.color
            align = rs.align(align_to)

            # í”„ë ˆì„ ìˆ˜ì§‘ ë° ì •ë ¬
            frames = pipeline.wait_for_frames()
            aligned_frames = align.process(frames)

            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()

            if not depth_frame or not color_frame:
                raise RuntimeError("âš ï¸ Failed to capture frames from Realsense.")

            # numpy ë°°ì—´ ë³€í™˜
            depth_map = np.asanyarray(depth_frame.get_data()).astype(np.float32)
            rgb_image = np.asanyarray(color_frame.get_data())

            pipeline.stop()

        except RuntimeError:
            print("No device connected (error during capture), using default intrinsics")
            profile = None
            depth_map = np.zeros((height, width), dtype=np.float32)  # ë¹ˆ Depth ë§µ ìƒì„±
            rgb_image = np.zeros((height, width, 3), dtype=np.uint8)  # ë¹ˆ RGB ì´ë¯¸ì§€ ìƒì„±

    return depth_map, rgb_image

#--------ì¤‘ë³µë°•ìŠ¤ ìˆëŠ”ì§€ ì²´í¬ 
def check_duplicate(results):
    seen = set()
    duplicates = False
    for result in results:
        if hasattr(result, "boxes") and result.boxes is not None:
            for box in result.boxes:
                cls_id = int(box.cls[0])
                if cls_id in seen:
                    duplicates = True
                else:
                    seen.add(cls_id)
    return duplicates # ë¶ˆë¦¬ì•ˆ ì•„ì›ƒí’‹ì„

#------- ì¤‘ë³µë°•ìŠ¤ ì—†ì• ê³  ê°€ê¹Œìš´ê²ƒë§Œ ë°˜í™˜
def remove_extra_box(results, depth_map):
    all_boxes = []  # ëª¨ë“  ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    # YOLO íƒì§€ ê²°ê³¼ì—ì„œ ëª¨ë“  ë°”ìš´ë”© ë°•ìŠ¤ ìˆ˜ì§‘ (í´ë˜ìŠ¤ ID í¬í•¨)
    for result in results:
        for box in result.boxes:
            bbox = tuple(map(int, box.xyxy[0]))  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
            cls_id = int(box.cls[0])  # í´ë˜ìŠ¤ ID ê°€ì ¸ì˜¤ê¸°
            all_boxes.append((cls_id, bbox))  # (í´ë˜ìŠ¤ ID, ë°”ìš´ë”© ë°•ìŠ¤) ì €ì¥

    # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ (None, None) ë°˜í™˜
    if not all_boxes:
        return (None, None)

    # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì°¾ê¸°
    return get_closest_box_with_depth(all_boxes, depth_map)


def get_closest_box_with_depth(boxes, depth_map):
    """ ê°€ì¥ ê°€ê¹Œìš´ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì„ íƒ (ìµœì†Œ Depth ê°’ ê¸°ì¤€) """
    min_depth = float("inf")
    closest_box = None
    closest_cls_id = None

    for cls_id, bbox in boxes:
        x1, y1, x2, y2 = bbox
        roi_depth = depth_map[y1:y2, x1:x2]  

        # 0ì´ ì•„ë‹Œ Depth ê°’ì´ ìˆìœ¼ë©´ ìµœì†Ÿê°’ ê³„ì‚° 
        valid_depths = roi_depth[roi_depth > 0]
        if len(valid_depths) > 0:
            min_roi_depth = np.min(valid_depths)  
            if min_roi_depth < min_depth:
                min_depth = min_roi_depth
                closest_box = bbox
                closest_cls_id = cls_id  # ê°€ì¥ ê°€ê¹Œìš´ ë°•ìŠ¤ì˜ í´ë˜ìŠ¤ ID ì €ì¥

    return (closest_cls_id, closest_box) 







def extract_plane_ransac(points, threshold=0.01, normal_threshold=0.95):
    """
    Depth ì´ë¯¸ì§€ì—ì„œ ì—¬ëŸ¬ í‰ë©´ì„ ì¶”ì¶œí•˜ê³ , ê° í‰ë©´ì˜ ìµœì†Œ Depth ê°’ì„ ê³„ì‚°í•˜ì—¬
    ê°€ì¥ ê°€ê¹Œìš´ í‰ë©´ì„ ì„ íƒí•©ë‹ˆë‹¤.
    :param depth_map: (H, W) í˜•íƒœì˜ Depth ì´ë¯¸ì§€
    :param intrinsic_matrix: ì¹´ë©”ë¼ ë‚´ì  í–‰ë ¬ (fx, fy, cx, cy í¬í•¨)
    :param threshold: RANSACì—ì„œ í‰ë©´ê³¼ì˜ ê±°ë¦¬ ê¸°ì¤€
    :param normal_threshold: ë…¸ë§ë²¡í„°ë‘ ë‚´ì í–‡ì„ë•Œ
    :return: ê°€ì¥ ê°€ê¹Œìš´ í‰ë©´ì— í•´ë‹¹í•˜ëŠ” í¬ì¸íŠ¸ë“¤ (inliers)
    """
    # pointsë¥¼ pcd ê°ì²´ë¡œ ë³€í™˜
    pcd = o3d.geometry.PointCloud()
    xyz = np.array([pt.position for pt in points])
    pcd.points = o3d.utility.Vector3dVector(xyz)

    # RANSACì„ ì´ìš©í•´ ì—¬ëŸ¬ í‰ë©´ ëª¨ë¸ ì¶”ì¶œ
    planes = []
    for _ in range(10):  # í‰ë©´ì„ nê°œ ì¶”ì¶œ

        #segment_plane: plane_model: ax + by + cz + d = 0ì—ì„œ ë¦¬ìŠ¤íŠ¸ [a, b, c, d] ë°˜í™˜
        #inliers = [3, 7, 12, 25, 48, 102, ...] ê°™ì€ ì¸ë±ìŠ¤
        plane_model, inliers = pcd.segment_plane(distance_threshold=threshold, ransac_n=3, num_iterations=1000)
        inlier_cloud = pcd.select_by_index(inliers)

        #(0, 1, 0)ì´ë‘ ë‚´ì 
        normal_vector = np.array(plane_model[:3])
        dot_product = np.dot(normal_vector, np.array([0, 1, 0]))  # (0, 1, 0) ë²¡í„°ì™€ì˜ ë‚´ì 

        # ë‚´ì ê°’ì´ ì„ê³„ê°’ ì´ìƒì´ë©´ ì¶”ê°€
        if dot_product > normal_threshold:
            planes.append((plane_model, inlier_cloud))

        # ì¶”ì¶œëœ í‰ë©´ì„ í¬ì¸íŠ¸í´ë¼ìš°ë“œì—ì„œ ì œì™¸ì‹œì¼œ ë‹¤ìŒ í‰ë©´ì„ ì°¾ê¸° ìœ„í•´
        pcd = pcd.select_by_index(inliers, invert=True)  
    
    # ê° í‰ë©´ì˜ Depth ê³„ì‚° (í‰ë©´ì— í¬í•¨ëœ ì ë“¤ì˜ ìµœì†Œ Depth ê°’)
    min_depth = float('inf')
    closest_plane = None
    closest_normal = None
    closest_inliers = None
    
    for plane_model, inlier_cloud in planes:
        # í‰ë©´ì— í¬í•¨ëœ ì ë“¤ì˜ ê¹Šì´ ê°’ ê³„ì‚°
        inlier_points = np.asarray(inlier_cloud.points)
        min_plane_depth = np.min(inlier_points[:, 2])  # Z ê°’ì´ Depthì— í•´ë‹¹
        
        # ê°€ì¥ ì‘ì€ Depth ê°’ì„ ê°€ì§„ í‰ë©´ì„ ì„ íƒ
        if min_plane_depth < min_depth:
            min_depth = min_plane_depth
            closest_plane = inlier_cloud
            closest_normal = np.array(plane_model[:3])
            closest_inliers = inlier_points

    
    return closest_plane, closest_normal, closest_inliers







#-----------ë°”ìš´ë”©ë°•ìŠ¤ì˜ ROI í¬ë¡­í•˜ê¸°
def crop_roi(bbox, rgb_image, depth_map):
    x1,y1,x2,y2 = bbox
    rgb_roi = rgb_image[y1:y2, x1:x2, :]
    depth_roi = depth_map[y1:y2, x1:x2]
    return rgb_roi, depth_roi


#--------- í´ë˜ìŠ¤ ë¶„ë¥˜í•´ì„œ í•¨ìˆ˜ ì‹¤í–‰ â—â—â—â—â—â—â—â—â—â—ìˆ˜ì •í•„ìš”
def measure_height(cls_id,rgb_roi, depth_roi, model):
    if cls_id ==0:
        angle, height = stairs.measure_height(depth_roi)
    #â—ë””ë²„ê¹…ìš©
    print("ë†’ì´ ì¸¡ì •ì¤‘")
    return angle, height









# ----------------------
# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
# ----------------------
if __name__ == "__main__":
    # ê°€ì •: color_img (BGR)ì™€ YOLOë¡œë¶€í„° ì–»ì€ bbox, ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì¤€ë¹„
    color_img = cv2.imread("test.jpg")
    yolo_bbox = (100, 200, 400, 500)  # ì˜ˆì‹œ (x1, y1, x2, y2)

    # ì˜ˆ: ì„ì˜ì˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ (PyTorch)
    # model = MySegModel(...)
    # model.load_state_dict(torch.load("model.pth"))
    # device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model.to(device)

    # ì—¬ê¸°ì„œëŠ” ë°ëª¨ë¼ì„œ model ëŒ€ì‹  None ì²˜ë¦¬
    model = None
    device = 'cpu'

    # ì„¸ê·¸ë©˜í…Œì´ì…˜ í•¨ìˆ˜ ì‹œì—° (ì‹¤ì œë¡œëŠ” modelì´ í•„ìš”)
    # segment_stairs_in_roi í•¨ìˆ˜ ë‚´ model ë¶€ë¶„ì„ ì§ì ‘ ìˆ˜ì •í•´ì„œ ì‚¬ìš© ê°€ëŠ¥
    # í˜¹ì€ ì•„ë˜ì²˜ëŸ¼ "ë”ë¯¸"ë¡œ ì˜ˆì‹œë¥¼ ë§Œë“¤ ìˆ˜ë„ ìˆìŒ
    def dummy_model(x):
        # ì…ë ¥ x: (1,3,h,w)
        # ê°€ì§œë¡œ ì „ë¶€ '1' í´ë˜ìŠ¤ë¼ê³  ì¹˜ì (ì „ë¶€ ê³„ë‹¨)
        return torch.zeros((1, 2, x.shape[2], x.shape[3]), device=x.device) + 0.5

    seg_model = dummy_model

    mask_roi = stairs.segment_stairs_in_roi(color_img, yolo_bbox, seg_model, device=device)
    
    # í›„ì†ì²˜ë¦¬
    edges, lines_p = stairs.postprocess_stair_mask(mask_roi)

    # ì‹œê°í™” ì˜ˆì‹œ
    # ROI ì˜ì—­ë§Œ ì‹œê°í™”
    x1, y1, x2, y2 = yolo_bbox
    roi_vis = color_img[y1:y2, x1:x2].copy()

    # ì—ì§€ ê·¸ë¦¬ê¸°
    edges_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    edges_bgr[edges != 0] = (0, 0, 255)  # ë¹¨ê°„ìƒ‰

    # lines_pê°€ ìˆìœ¼ë©´ ì§ì„  ì‹œê°í™”
    if lines_p is not None:
        for line in lines_p:
            x_start, y_start, x_end, y_end = line[0]
            cv2.line(roi_vis, (x_start, y_start), (x_end, y_end), (0,255,0), 2)

    # ê²°ê³¼ ë³´ê¸°
    cv2.imshow("ROI mask", mask_roi*255)  # 0 or 1 => ì‹œê°í™”ë¥¼ ìœ„í•´ 255 ê³±
    cv2.imshow("ROI edges", edges_bgr)
    cv2.imshow("ROI lines", roi_vis)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
