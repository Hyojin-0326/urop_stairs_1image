import numpy as np
import cv2
import pyrealsense2 as rs
import torch
import stairs
import os
import open3d as o3d




class Config:
    fx, fy, cx, cy = 605.9815, 606.1337, 308.5001, 246.4238
    intrinsic_matrix = intrinsic_matrix = np.array([
    [fx,  0, cx],  # ì´ˆì  ê±°ë¦¬ fx, ì£¼ì (cx)
    [ 0, fy, cy],  # ì´ˆì  ê±°ë¦¬ fy, ì£¼ì (cy)
    [ 0,  0,  1]   # ë³€í™˜ì„ ìœ„í•œ ë§ˆì§€ë§‰ í–‰ (ê³ ì •)
])
    depth_scale = 0.001



def depth_to_pointcloud(depth_map, intrinsic_matrix=Config.intrinsic_matrix, depth_scale=Config.depth_scale):
    """
    Open3Dë¥¼ ì‚¬ìš©í•˜ì—¬ Depth ì´ë¯¸ì§€ë¥¼ í¬ì¸íŠ¸í´ë¼ìš°ë“œë¡œ ë³€í™˜.
    :param depth_map: (H, W) í˜•íƒœì˜ NumPy ë°°ì—´ (Depth ì´ë¯¸ì§€)
    :param intrinsic_matrix: 3x3 í˜•íƒœì˜ ì¹´ë©”ë¼ ë‚´ì  í–‰ë ¬ (fx, fy, cx, cy í¬í•¨)
    :param depth_scale: Depth ê°’ì˜ ìŠ¤ì¼€ì¼ë§ (RealSenseëŠ” 1000.0ì„ ì‚¬ìš©)
    :return: Open3D PointCloud ê°ì²´
    """
    # âœ… CUDA ì—°ì‚° ì—†ì´ ë°”ë¡œ Open3D Tensorë¡œ ë³€í™˜ (PyTorch X)
    depth_o3d = o3d.core.Tensor(depth_map.astype(np.float32) / depth_scale, dtype=o3d.core.Dtype.Float32)

    # âœ… Open3Dì˜ Tensor ê¸°ë°˜ Intrinsic ì„¤ì • (GPU ìµœì í™”ë¨)
    intrinsic_o3d = o3d.core.Tensor(intrinsic_matrix, dtype=o3d.core.Dtype.Float64)

    # âœ… Open3D GPU ê¸°ë°˜ ë³€í™˜ (to_legacy() ì‚¬ìš© ì•ˆ í•¨)
    pcd = o3d.t.geometry.PointCloud.create_from_depth_image(depth_o3d, intrinsic_o3d)

    return pcd  # âœ… Open3D GPU í¬ì¸íŠ¸í´ë¼ìš°ë“œ ìœ ì§€


#----------------- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_rgb_from_bin(bin_path, frame_idx, height=480, width=640):
    data_path = os.path.dirname(os.path.abspath(__file__))
    meta_path = os.path.join(data_path, "data", "meta.txt")

    # ğŸ”¹ 1) meta.txtì—ì„œ í”„ë ˆì„ ê°œìˆ˜ ì½ê¸°
    try:
        with open(meta_path, "r") as f:
            total_frames = int(f.readline().strip())  # ì²« ë²ˆì§¸ ì¤„ì— ì €ì¥ëœ í”„ë ˆì„ ê°œìˆ˜ ì½ê¸°
    except FileNotFoundError:
        raise FileNotFoundError(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ {meta_path}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    except ValueError:
        raise ValueError(f"âŒ {meta_path}ì—ì„œ í”„ë ˆì„ ê°œìˆ˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

    # ğŸ”¹ 2) frame_idxê°€ ìœ íš¨í•œì§€ í™•ì¸
    if frame_idx >= total_frames or frame_idx < 0:
        raise ValueError(f"âš ï¸ frame_idx {frame_idx}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤! (ì´ {total_frames}ê°œ í”„ë ˆì„)")

    # ğŸ”¹ 3) .bin íŒŒì¼ì—ì„œ RGB ë°ì´í„° ë¡œë“œ
    try:
        rgb_data = np.fromfile(bin_path, dtype=np.uint8)

        # ì „ì²´ ë°ì´í„°ê°€ (total_frames, H, W, 3) í¬ê¸°ì¸ì§€ í™•ì¸
        expected_size = total_frames * height * width * 3
        if len(rgb_data) != expected_size:
            raise ValueError(f"âŒ RGB ë°ì´í„° í¬ê¸° ë¶ˆì¼ì¹˜! ì˜ˆìƒ {expected_size}, ì‹¤ì œ {len(rgb_data)}")

        # ğŸ”¹ 4) (í”„ë ˆì„ ê°œìˆ˜, H, W, 3) í˜•íƒœë¡œ reshape
        rgb_data = rgb_data.reshape((total_frames, height, width, 3))

        # ğŸ”¹ 5) frame_idxì— í•´ë‹¹í•˜ëŠ” í”„ë ˆì„ ë°˜í™˜
        rgb_image = rgb_data[frame_idx]

    except Exception as e:
        raise RuntimeError(f"âŒ RGB .bin íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return rgb_image



def align_depth_to_rgb(depth_bin_path, rgb_bin_path, frame_idx, height=480, width=640):
    context = rs.context()
    devices = context.query_devices()
    data_path = os.path.dirname(os.path.abspath(__file__))
    meta_path = os.path.join(data_path, "data", "meta.txt")
    try:
        with open(meta_path, "r") as f:
            total_frames = int(f.readline().strip())  # ì²« ì¤„ì—ì„œ í”„ë ˆì„ ê°œìˆ˜ ì½ê¸°
        print(f"ğŸ”¹ meta.txtì—ì„œ ì½ì€ í”„ë ˆì„ ê°œìˆ˜: {total_frames}")
    except FileNotFoundError:
        raise FileNotFoundError(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ {meta_path}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    except ValueError:
        raise ValueError(f"âŒ {meta_path}ì—ì„œ í”„ë ˆì„ ê°œìˆ˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

    if len(devices) == 0:
        print("ğŸ”¹ No device connected, using default intrinsics & loading from .bin files")
        intrinsics = rs.intrinsics()
        intrinsics.width = width
        intrinsics.height = height
        intrinsics.ppx = 308.5001  # ê¸°ë³¸ ê´‘í•™ ì¤‘ì‹¬ X (cx)
        intrinsics.ppy = 246.4238  # ê¸°ë³¸ ê´‘í•™ ì¤‘ì‹¬ Y (cy)
        intrinsics.fx = 605.9815  # ê¸°ë³¸ ì´ˆì  ê±°ë¦¬ X (fx)
        intrinsics.fy = 606.1337  # ê¸°ë³¸ ì´ˆì  ê±°ë¦¬ Y (fy)
        intrinsics.model = rs.distortion.none  # ì™œê³¡ ì—†ìŒ
        intrinsics.coeffs = [0, 0, 0, 0, 0]  
        
        # --- .bin íŒŒì¼ì—ì„œ RGB & Depth ë¶ˆëŸ¬ì˜¤ê¸° ---
        depth_map = np.fromfile(depth_bin_path, dtype=np.float32)
        depth_map = depth_map.reshape((total_frames, height, width))
        depth_map = depth_map[frame_idx]

        rgb_image = load_rgb_from_bin(rgb_bin_path, frame_idx)

        if frame_idx >= total_frames:
            raise ValueError(f"âš ï¸ frame_idx {frame_idx}ê°€ ì €ì¥ëœ í”„ë ˆì„ ê°œìˆ˜ {total_frames}ë³´ë‹¤ í¼")

    else:
        try:
            print("âœ… Realsense device detected, capturing frames...")
            pipeline = rs.pipeline()
            config = rs.config()
            config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
            config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
            profile = pipeline.start(config)

            # ì¹´ë©”ë¼ Intrinsics ê°€ì ¸ì˜¤ê¸°
            color_profile = profile.get_stream(rs.stream.color)
            intr = color_profile.as_video_stream_profile().get_intrinsics()
            fx, fy, cx, cy = intr.fx, intr.fy, intr.ppx, intr.ppy

            # Depth â†’ RGB ì •ë ¬ ìˆ˜í–‰
            align_to = rs.stream.color
            align = rs.align(align_to)

            # í”„ë ˆì„ ìˆ˜ì§‘ ë° ì •ë ¬
            frames = pipeline.wait_for_frames()
            aligned_frames = align.process(frames)

            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()

            if not depth_frame or not color_frame:
                raise RuntimeError("âš ï¸ Failed to capture frames from Realsense.")

            # numpy ë°°ì—´ ë³€í™˜
            depth_map = np.asanyarray(depth_frame.get_data()).astype(np.float32)
            rgb_image = np.asanyarray(color_frame.get_data())

            pipeline.stop()

        except RuntimeError:
            print("No device connected (error during capture), using default intrinsics")
            profile = None
            depth_map = np.zeros((height, width), dtype=np.float32)  # ë¹ˆ Depth ë§µ ìƒì„±
            rgb_image = np.zeros((height, width, 3), dtype=np.uint8)  # ë¹ˆ RGB ì´ë¯¸ì§€ ìƒì„±

    return depth_map, rgb_image

#--------ì¤‘ë³µë°•ìŠ¤ ìˆëŠ”ì§€ ì²´í¬ 
def check_duplicate(results):
    seen = set()
    duplicates = False
    for result in results:
        if hasattr(result, "boxes") and result.boxes is not None:
            for box in result.boxes:
                cls_id = int(box.cls[0])
                if cls_id in seen:
                    duplicates = True
                else:
                    seen.add(cls_id)
    return duplicates # ë¶ˆë¦¬ì•ˆ ì•„ì›ƒí’‹ì„

#------- ì¤‘ë³µë°•ìŠ¤ ì—†ì• ê³  ê°€ê¹Œìš´ê²ƒë§Œ ë°˜í™˜
def remove_extra_box(results, depth_map):
    all_boxes = []  # ëª¨ë“  ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    # YOLO íƒì§€ ê²°ê³¼ì—ì„œ ëª¨ë“  ë°”ìš´ë”© ë°•ìŠ¤ ìˆ˜ì§‘ (í´ë˜ìŠ¤ ID í¬í•¨)
    for result in results:
        for box in result.boxes:
            bbox = tuple(map(int, box.xyxy[0]))  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
            cls_id = int(box.cls[0])  # í´ë˜ìŠ¤ ID ê°€ì ¸ì˜¤ê¸°
            all_boxes.append((cls_id, bbox))  # (í´ë˜ìŠ¤ ID, ë°”ìš´ë”© ë°•ìŠ¤) ì €ì¥

    # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ (None, None) ë°˜í™˜
    if not all_boxes:
        return (None, None)

    # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì°¾ê¸°
    return get_closest_box_with_depth(all_boxes, depth_map)


def get_closest_box_with_depth(boxes, depth_map):
    """ ê°€ì¥ ê°€ê¹Œìš´ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì„ íƒ (ìµœì†Œ Depth ê°’ ê¸°ì¤€) """
    min_depth = float("inf")
    closest_box = None
    closest_cls_id = None

    for cls_id, bbox in boxes:
        x1, y1, x2, y2 = bbox
        roi_depth = depth_map[y1:y2, x1:x2]  

        # 0ì´ ì•„ë‹Œ Depth ê°’ì´ ìˆìœ¼ë©´ ìµœì†Ÿê°’ ê³„ì‚° 
        valid_depths = roi_depth[roi_depth > 0]
        if len(valid_depths) > 0:
            min_roi_depth = np.min(valid_depths)  
            if min_roi_depth < min_depth:
                min_depth = min_roi_depth
                closest_box = bbox
                closest_cls_id = cls_id  # ê°€ì¥ ê°€ê¹Œìš´ ë°•ìŠ¤ì˜ í´ë˜ìŠ¤ ID ì €ì¥

    return (closest_cls_id, closest_box) 

def extract_plane_ransac(depth_map, intrinsic_matrix=Config.intrinsic_matrix, threshold=0.01):
    """
    Depth ì´ë¯¸ì§€ì—ì„œ ì—¬ëŸ¬ í‰ë©´ì„ ì¶”ì¶œí•˜ê³ , ê° í‰ë©´ì˜ ìµœì†Œ Depth ê°’ì„ ê³„ì‚°í•˜ì—¬
    ê°€ì¥ ê°€ê¹Œìš´ í‰ë©´ì„ ì„ íƒí•©ë‹ˆë‹¤.
    :param depth_map: (H, W) í˜•íƒœì˜ Depth ì´ë¯¸ì§€
    :param intrinsic_matrix: ì¹´ë©”ë¼ ë‚´ì  í–‰ë ¬ (fx, fy, cx, cy í¬í•¨)
    :param threshold: RANSACì—ì„œ í‰ë©´ê³¼ì˜ ê±°ë¦¬ ê¸°ì¤€
    :return: ê°€ì¥ ê°€ê¹Œìš´ í‰ë©´ì— í•´ë‹¹í•˜ëŠ” í¬ì¸íŠ¸ë“¤ (inliers)
    """
    # Depth ì´ë¯¸ì§€ë¥¼ í¬ì¸íŠ¸í´ë¼ìš°ë“œë¡œ ë³€í™˜
    pcd = depth_to_pointcloud(depth_map, intrinsic_matrix)
    
    # RANSACì„ ì´ìš©í•´ ì—¬ëŸ¬ í‰ë©´ ëª¨ë¸ ì¶”ì¶œ
    planes = []
    for _ in range(10):  # í‰ë©´ì„ ì—¬ëŸ¬ ê°œ ì¶”ì¶œ (ì˜ˆ: 10ë²ˆ ë°˜ë³µ)
        plane_model, inliers = pcd.segment_plane(distance_threshold=threshold, ransac_n=3, num_iterations=1000)
        inlier_cloud = pcd.select_by_index(inliers)
        planes.append((plane_model, inlier_cloud))
        
        # ì¶”ì¶œëœ í‰ë©´ì„ í¬ì¸íŠ¸í´ë¼ìš°ë“œì—ì„œ ì œì™¸ì‹œì¼œ ë‹¤ìŒ í‰ë©´ì„ ì°¾ê¸° ìœ„í•´
        pcd = pcd.select_by_index(inliers, invert=True)  
    
    # ê° í‰ë©´ì˜ Depth ê³„ì‚° (í‰ë©´ì— í¬í•¨ëœ ì ë“¤ì˜ ìµœì†Œ Depth ê°’)
    min_depth = float('inf')
    closest_plane = None
    
    for plane_model, inlier_cloud in planes:
        # í‰ë©´ì— í¬í•¨ëœ ì ë“¤ì˜ ê¹Šì´ ê°’ ê³„ì‚°
        inlier_points = np.asarray(inlier_cloud.points)
        min_plane_depth = np.min(inlier_points[:, 2])  # Z ê°’ì´ Depthì— í•´ë‹¹
        
        # ê°€ì¥ ì‘ì€ Depth ê°’ì„ ê°€ì§„ í‰ë©´ì„ ì„ íƒ
        if min_plane_depth < min_depth:
            min_depth = min_plane_depth
            closest_plane = inlier_cloud
    
    return closest_plane






#-----------ë°”ìš´ë”©ë°•ìŠ¤ì˜ ROI í¬ë¡­í•˜ê¸°
def crop_roi(bbox, rgb_image, depth_map):
    x1,y1,x2,y2 = bbox
    rgb_roi = rgb_image[y1:y2, x1:x2, :]
    depth_roi = depth_map[y1:y2, x1:x2]
    return rgb_roi, depth_roi


#--------- í´ë˜ìŠ¤ ë¶„ë¥˜í•´ì„œ í•¨ìˆ˜ ì‹¤í–‰ â—â—â—â—â—â—â—â—â—â—ìˆ˜ì •í•„ìš”
def measure_height(cls_id,rgb_roi, depth_roi, model):
    if cls_id ==0:
        angle, height = stairs.measure_height(depth_roi)
    #â—ë””ë²„ê¹…ìš©
    print("ë†’ì´ ì¸¡ì •ì¤‘")
    return angle, height









# ----------------------
# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
# ----------------------
if __name__ == "__main__":
    # ê°€ì •: color_img (BGR)ì™€ YOLOë¡œë¶€í„° ì–»ì€ bbox, ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì¤€ë¹„
    color_img = cv2.imread("test.jpg")
    yolo_bbox = (100, 200, 400, 500)  # ì˜ˆì‹œ (x1, y1, x2, y2)

    # ì˜ˆ: ì„ì˜ì˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ (PyTorch)
    # model = MySegModel(...)
    # model.load_state_dict(torch.load("model.pth"))
    # device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model.to(device)

    # ì—¬ê¸°ì„œëŠ” ë°ëª¨ë¼ì„œ model ëŒ€ì‹  None ì²˜ë¦¬
    model = None
    device = 'cpu'

    # ì„¸ê·¸ë©˜í…Œì´ì…˜ í•¨ìˆ˜ ì‹œì—° (ì‹¤ì œë¡œëŠ” modelì´ í•„ìš”)
    # segment_stairs_in_roi í•¨ìˆ˜ ë‚´ model ë¶€ë¶„ì„ ì§ì ‘ ìˆ˜ì •í•´ì„œ ì‚¬ìš© ê°€ëŠ¥
    # í˜¹ì€ ì•„ë˜ì²˜ëŸ¼ "ë”ë¯¸"ë¡œ ì˜ˆì‹œë¥¼ ë§Œë“¤ ìˆ˜ë„ ìˆìŒ
    def dummy_model(x):
        # ì…ë ¥ x: (1,3,h,w)
        # ê°€ì§œë¡œ ì „ë¶€ '1' í´ë˜ìŠ¤ë¼ê³  ì¹˜ì (ì „ë¶€ ê³„ë‹¨)
        return torch.zeros((1, 2, x.shape[2], x.shape[3]), device=x.device) + 0.5

    seg_model = dummy_model

    mask_roi = stairs.segment_stairs_in_roi(color_img, yolo_bbox, seg_model, device=device)
    
    # í›„ì†ì²˜ë¦¬
    edges, lines_p = stairs.postprocess_stair_mask(mask_roi)

    # ì‹œê°í™” ì˜ˆì‹œ
    # ROI ì˜ì—­ë§Œ ì‹œê°í™”
    x1, y1, x2, y2 = yolo_bbox
    roi_vis = color_img[y1:y2, x1:x2].copy()

    # ì—ì§€ ê·¸ë¦¬ê¸°
    edges_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    edges_bgr[edges != 0] = (0, 0, 255)  # ë¹¨ê°„ìƒ‰

    # lines_pê°€ ìˆìœ¼ë©´ ì§ì„  ì‹œê°í™”
    if lines_p is not None:
        for line in lines_p:
            x_start, y_start, x_end, y_end = line[0]
            cv2.line(roi_vis, (x_start, y_start), (x_end, y_end), (0,255,0), 2)

    # ê²°ê³¼ ë³´ê¸°
    cv2.imshow("ROI mask", mask_roi*255)  # 0 or 1 => ì‹œê°í™”ë¥¼ ìœ„í•´ 255 ê³±
    cv2.imshow("ROI edges", edges_bgr)
    cv2.imshow("ROI lines", roi_vis)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
