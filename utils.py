import numpy as np
import cv2
import pyrealsense2 as rs
from scipy.spatial import KDTree
from sklearn.neighbors import NearestNeighbors
import torch
import stairs
import os
import open3d as o3d
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D




class Config:
    fx, fy, cx, cy = 605.9815, 606.1337, 308.5001, 246.4238
    intrinsic_matrix = intrinsic_matrix = np.array([
    [fx,  0, cx],  # Ï¥àÏ†ê Í±∞Î¶¨ fx, Ï£ºÏ†ê(cx)
    [ 0, fy, cy],  # Ï¥àÏ†ê Í±∞Î¶¨ fy, Ï£ºÏ†ê(cy)
    [ 0,  0,  1]   # Î≥ÄÌôòÏùÑ ÏúÑÌïú ÎßàÏßÄÎßâ Ìñâ (Í≥†Ï†ï)
    
])
    intrinsics = 605.9815, 606.1337, 308.5001, 246.4238
    depth_scale = 1000
    k = 10
    threshold = 0.9
    voxel_size = 50

class Point:
    def __init__(self, position, normal=None, isGround=False):
        self.position = position
        self.normal = normal
        self.isGround = isGround

class VoxelGrid:
    def __init__(self, points, voxel_size):
        self.voxel_size = voxel_size
        self.points = points
        self.voxel_grid = {}
        for i, pt in enumerate(points):
            voxel_key = tuple(np.floor(pt.position / voxel_size).astype(int))
            if voxel_key not in self.voxel_grid:
                self.voxel_grid[voxel_key] = []
            self.voxel_grid[voxel_key].append(i)
        
        # Building a k-d tree for fast k-NN search
        self.tree = NearestNeighbors(n_neighbors=Config.k, algorithm='kd_tree')
        point_positions = np.array([pt.position for pt in points])  # assuming pt.position is a 3D vector
        self.tree.fit(point_positions)

    def getKNN(self, position, k, search_radius, points):
        # Use the k-d tree to find k nearest neighbors within the search radius
        distances, indices = self.tree.radius_neighbors([position], radius=search_radius)
        
        # Filter out the neighbors that are beyond the search radius
        neighbors = [idx for idx in indices[0] if np.linalg.norm(points[idx].position - position) <= search_radius]
        
        return neighbors[:k]  # return the first k neighbors


def preprocessPointCloud(points, voxel_size=Config.voxel_size, k=Config.k, threshold=Config.threshold):
    grid = VoxelGrid(points, voxel_size)
    search_radius = voxel_size * 1.5

    # Using the bottom 80% of the point cloud
    min_y = np.min([pt.position[1] for pt in points])
    max_y = np.max([pt.position[1] for pt in points])
    bottom_80_percent = min_y + (max_y - min_y) * 0.2  # 20% ÏßÄÏ†êÎ∂ÄÌÑ∞ ÌïòÎã® 80%

    points_bottom_80 = [pt for pt in points if pt.position[1] <= bottom_80_percent]

    for pt in points_bottom_80:
        neighbors = grid.getKNN(pt.position, k, search_radius, points)
        
        if len(neighbors) < k:
            pt.isGround = False
            continue
        
        # Compute covariance matrix
        mean = np.mean([points[idx].position for idx in neighbors], axis=0)
        covariance = np.cov([points[idx].position - mean for idx in neighbors], rowvar=False)

        # Eigen decomposition
        eigvals, eigvecs = np.linalg.eigh(covariance)
        normal = eigvecs[:, np.argmin(eigvals)]  # Smallest eigenvalue corresponds to normal

        if normal[2] < 0:
            normal = -normal
        pt.normal = normal
        pt.isGround = np.dot(normal, np.array([0, 0, 1])) > threshold

    # Remove ground points
    points_without_ground = [pt for pt in points if not pt.isGround]
    ground_points = [pt for pt in points if pt.isGround]
    return points_without_ground, ground_points

def preprocess_RGBimg(rgb_image, points, ground_points, intrinsics = Config.intrinsics):
    """
    RGB Ïù¥ÎØ∏ÏßÄÏóêÏÑú Í∑∏ÎùºÏö¥Îìú ÌîåÎ†àÏù∏Ïóê Ìï¥ÎãπÌïòÎäî Ìè¨Ïù∏Ìä∏Î•º ÎÇ†Î¶¨Îäî Ìï®Ïàò.
    
    :param rgb_image: ÏõêÎ≥∏ RGB Ïù¥ÎØ∏ÏßÄ
    :param points: Ï†ÑÏ≤¥ Ìè¨Ïù∏Ìä∏ ÌÅ¥ÎùºÏö∞Îìú
    :param ground_points: Í∑∏ÎùºÏö¥ÎìúÎ°ú ÌåêÎã®Îêú Ìè¨Ïù∏Ìä∏Îì§Ïùò Ïù∏Îç±Ïä§
    :param intrinsics: Ïπ¥Î©îÎùº ÎÇ¥Ïû¨ ÌååÎùºÎØ∏ÌÑ∞ (fx, fy, cx, cy)
    :return: Í∑∏ÎùºÏö¥Îìú ÌîåÎ†àÏù∏Ïù¥ Ï†úÍ±∞Îêú RGB Ïù¥ÎØ∏ÏßÄ
    """
    # ÎßåÏïΩ pointsÍ∞Ä Î¶¨Ïä§Ìä∏ÎùºÎ©¥ numpy Î∞∞Ïó¥Î°ú Î≥ÄÌôò
    points = np.array([pt.position for pt in points]) if isinstance(points, list) else points

    # 3D Ìè¨Ïù∏Ìä∏Î•º 2D Ïù¥ÎØ∏ÏßÄÎ°ú Ìà¨ÏòÅ
    ground_3d_points = points[ground_points]  # ground_pointsÎäî Ïù∏Îç±Ïä§ Î¶¨Ïä§Ìä∏Ïó¨Ïïº Ìï®
    ground_2d_points = project_to_2d(ground_3d_points, intrinsics)

    # 2D Ï¢åÌëúÎ•º Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ ÎÇ¥ÏóêÏÑú Ïú†Ìö®Ìïú Í∞íÏúºÎ°ú ÌÅ¥Î¶¨Ìïë
    h, w, _ = rgb_image.shape
    u, v = ground_2d_points[:, 0], ground_2d_points[:, 1]
    u = np.clip(u.astype(int), 0, w - 1)
    v = np.clip(v.astype(int), 0, h - 1)

    # Í∑∏ÎùºÏö¥Îìú Ìè¨Ïù∏Ìä∏Ïóê Ìï¥ÎãπÌïòÎäî ÌîΩÏÖÄÏùÑ ÎßàÏä§ÌÅ¨Î°ú ÏÑ§Ï†ï
    mask = np.zeros((h, w), dtype=np.uint8)
    mask[v, u] = 1

    # Í∑∏ÎùºÏö¥Îìú ÏòÅÏó≠ÏùÑ Ï†úÍ±∞ÌïòÍ±∞ÎÇò ÎåÄÏ≤¥ (Ïòà: 0ÏúºÎ°ú ÎßàÏä§ÌÇπ)
    rgb_image[mask == 1] = 0  # Í∑∏ÎùºÏö¥Îìú Î∂ÄÎ∂ÑÏùÑ Í≤ÄÏ†ïÏÉâÏúºÎ°ú ÎåÄÏ≤¥

    return rgb_image



def depth_to_pointcloud(depth_map, intrinsic_matrix=Config.intrinsics, depth_scale=Config.depth_scale):
    """
    Open3DÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Depth Ïù¥ÎØ∏ÏßÄÎ•º Ìè¨Ïù∏Ìä∏ÌÅ¥ÎùºÏö∞ÎìúÎ°ú Î≥ÄÌôò.
    :param depth_map: (H, W) ÌòïÌÉúÏùò NumPy Î∞∞Ïó¥ (Depth Ïù¥ÎØ∏ÏßÄ)
    :param intrinsic_matrix: 3x3 ÌòïÌÉúÏùò Ïπ¥Î©îÎùº ÎÇ¥Ï†Å ÌñâÎ†¨ (fx, fy, cx, cy Ìè¨Ìï®)
    :param depth_scale: Depth Í∞íÏùò Ïä§ÏºÄÏùºÎßÅ (RealSenseÎäî 1000.0ÏùÑ ÏÇ¨Ïö©)
    :return: Open3D PointCloud Í∞ùÏ≤¥
    """
    # ‚úÖ CUDA Ïó∞ÏÇ∞ ÏóÜÏù¥ Î∞îÎ°ú Open3D TensorÎ°ú Î≥ÄÌôò (PyTorch X)
    depth_o3d = o3d.core.Tensor(depth_map.astype(np.float32) / depth_scale, dtype=o3d.core.Dtype.Float32)

    # ‚úÖ Open3DÏùò Tensor Í∏∞Î∞ò Intrinsic ÏÑ§Ï†ï (GPU ÏµúÏ†ÅÌôîÎê®)
    intrinsic_o3d = o3d.core.Tensor(intrinsic_matrix, dtype=o3d.core.Dtype.Float64)

    # ‚úÖ Open3D GPU Í∏∞Î∞ò Î≥ÄÌôò (to_legacy() ÏÇ¨Ïö© Ïïà Ìï®)
    pcd = o3d.t.geometry.PointCloud.create_from_depth_image(depth_o3d, intrinsic_o3d)
    #points = pcd.point.positions.numpy()  # NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôò
    #return points
    return pcd

def project_to_2d(points, depth_scale = Config.depth_scale,intrinsics=Config.intrinsics): 
    """
    3D Ìè¨Ïù∏Ìä∏Î•º 2D RGB Ïù¥ÎØ∏ÏßÄÎ°ú Ìà¨ÏòÅÌïòÎäî Ìï®Ïàò.
    
    :param points: 3D Ìè¨Ïù∏Ìä∏ (N x 3) numpy Î∞∞Ïó¥
    :param intrinsics: Ïπ¥Î©îÎùºÏùò ÎÇ¥Ïû¨ ÌååÎùºÎØ∏ÌÑ∞ (fx, fy, cx, cy)
    :return: 2D Ïù¥ÎØ∏ÏßÄ Ï¢åÌëú (u, v)
    """
    fx, fy, cx, cy = intrinsics
    u = (points[:, 0] * fx / points[:, 2]) + cx
    v = (points[:, 1] * fy / points[:, 2]) + cy
    return np.column_stack((u, v))


# def pointcloud_visualization(points, save_path="pointcloud_plot.png"):
#     fig = plt.figure(figsize=(10, 7))
#     ax = fig.add_subplot(111, projection='3d')

#     # X, Y, Z Ï¢åÌëúÎ•º ÏÇ∞Ï†êÎèÑÎ°ú ÌëúÌòÑ
#     ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=1, color='b')

#     # Ï∂ï Î†àÏù¥Î∏î
#     ax.set_xlabel('X')
#     ax.set_ylabel('Y')
#     ax.set_zlabel('Z')

#     # ÌîåÎ°Ø Î≥¥Ïó¨Ï£ºÍ∏∞ (ÌååÏùºÎ°ú Ï†ÄÏû•ÎèÑ Í∞ÄÎä•)
#     plt.savefig(save_path, dpi=300)
#     plt.close()

#     print(f"Ìè¨Ïù∏Ìä∏ ÌÅ¥ÎùºÏö∞Îìú Ïù¥ÎØ∏ÏßÄÍ∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: {save_path}")

def pointcloud_visualization(points):
    # Open3D Ìè¨Ïù∏Ìä∏ÌÅ¥ÎùºÏö∞Îìú Í∞ùÏ≤¥ ÏÉùÏÑ±
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points)  # NumPy -> Open3D Î≥ÄÌôò

    # 3D ÏãúÍ∞ÅÌôî Ïã§Ìñâ
    o3d.visualization.draw_geometries([pcd])



#----------------- Îç∞Ïù¥ÌÑ∞ Î°úÎìú Ìï®Ïàò
def load_rgb_from_bin(bin_path, frame_idx, height=480, width=640):
    data_path = os.path.dirname(os.path.abspath(__file__))
    meta_path = os.path.join(data_path, "data", "meta.txt")

    # üîπ 1) meta.txtÏóêÏÑú ÌîÑÎ†àÏûÑ Í∞úÏàò ÏùΩÍ∏∞
    try:
        with open(meta_path, "r") as f:
            total_frames = int(f.readline().strip())  # Ï≤´ Î≤àÏß∏ Ï§ÑÏóê Ï†ÄÏû•Îêú ÌîÑÎ†àÏûÑ Í∞úÏàò ÏùΩÍ∏∞
    except FileNotFoundError:
        raise FileNotFoundError(f"‚ùå Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌååÏùº {meta_path}ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")
    except ValueError:
        raise ValueError(f"‚ùå {meta_path}ÏóêÏÑú ÌîÑÎ†àÏûÑ Í∞úÏàòÎ•º ÏùΩÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")

    # üîπ 2) frame_idxÍ∞Ä Ïú†Ìö®ÌïúÏßÄ ÌôïÏù∏
    if frame_idx >= total_frames or frame_idx < 0:
        raise ValueError(f"‚ö†Ô∏è frame_idx {frame_idx}Í∞Ä Ïú†Ìö®ÌïòÏßÄ ÏïäÏäµÎãàÎã§! (Ï¥ù {total_frames}Í∞ú ÌîÑÎ†àÏûÑ)")

    # üîπ 3) .bin ÌååÏùºÏóêÏÑú RGB Îç∞Ïù¥ÌÑ∞ Î°úÎìú
    try:
        rgb_data = np.fromfile(bin_path, dtype=np.uint8)

        # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Í∞Ä (total_frames, H, W, 3) ÌÅ¨Í∏∞Ïù∏ÏßÄ ÌôïÏù∏
        expected_size = total_frames * height * width * 3
        if len(rgb_data) != expected_size:
            raise ValueError(f"‚ùå RGB Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ Î∂àÏùºÏπò! ÏòàÏÉÅ {expected_size}, Ïã§Ï†ú {len(rgb_data)}")

        # üîπ 4) (ÌîÑÎ†àÏûÑ Í∞úÏàò, H, W, 3) ÌòïÌÉúÎ°ú reshape
        rgb_data = rgb_data.reshape((total_frames, height, width, 3))

        # üîπ 5) frame_idxÏóê Ìï¥ÎãπÌïòÎäî ÌîÑÎ†àÏûÑ Î∞òÌôò
        rgb_image = rgb_data[frame_idx]

    except Exception as e:
        raise RuntimeError(f"‚ùå RGB .bin ÌååÏùºÏùÑ Î°úÎìúÌïòÎäî Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")

    return rgb_image



def align_depth_to_rgb(depth_bin_path, rgb_bin_path, frame_idx, height=480, width=640):
    context = rs.context()
    devices = context.query_devices()
    data_path = os.path.dirname(os.path.abspath(__file__))
    meta_path = os.path.join(data_path, "data", "meta.txt")
    try:
        with open(meta_path, "r") as f:
            total_frames = int(f.readline().strip())  # Ï≤´ Ï§ÑÏóêÏÑú ÌîÑÎ†àÏûÑ Í∞úÏàò ÏùΩÍ∏∞
        print(f"üîπ meta.txtÏóêÏÑú ÏùΩÏùÄ ÌîÑÎ†àÏûÑ Í∞úÏàò: {total_frames}")
    except FileNotFoundError:
        raise FileNotFoundError(f"‚ùå Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌååÏùº {meta_path}ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")
    except ValueError:
        raise ValueError(f"‚ùå {meta_path}ÏóêÏÑú ÌîÑÎ†àÏûÑ Í∞úÏàòÎ•º ÏùΩÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")

    if len(devices) == 0:
        print("üîπ No device connected, using default intrinsics & loading from .bin files")
        intrinsics = rs.intrinsics()
        intrinsics.width = width
        intrinsics.height = height
        intrinsics.ppx = 308.5001  # Í∏∞Î≥∏ Í¥ëÌïô Ï§ëÏã¨ X (cx)
        intrinsics.ppy = 246.4238  # Í∏∞Î≥∏ Í¥ëÌïô Ï§ëÏã¨ Y (cy)
        intrinsics.fx = 605.9815  # Í∏∞Î≥∏ Ï¥àÏ†ê Í±∞Î¶¨ X (fx)
        intrinsics.fy = 606.1337  # Í∏∞Î≥∏ Ï¥àÏ†ê Í±∞Î¶¨ Y (fy)
        intrinsics.model = rs.distortion.none  # ÏôúÍ≥° ÏóÜÏùå
        intrinsics.coeffs = [0, 0, 0, 0, 0]  
        
        # --- .bin ÌååÏùºÏóêÏÑú RGB & Depth Î∂àÎü¨Ïò§Í∏∞ ---
        depth_map = np.fromfile(depth_bin_path, dtype=np.float32)
        depth_map = depth_map.reshape((total_frames, height, width))
        depth_map = depth_map[frame_idx]

        rgb_image = load_rgb_from_bin(rgb_bin_path, frame_idx)

        if frame_idx >= total_frames:
            raise ValueError(f"‚ö†Ô∏è frame_idx {frame_idx}Í∞Ä Ï†ÄÏû•Îêú ÌîÑÎ†àÏûÑ Í∞úÏàò {total_frames}Î≥¥Îã§ ÌÅº")

    else:
        try:
            print("‚úÖ Realsense device detected, capturing frames...")
            pipeline = rs.pipeline()
            config = rs.config()
            config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
            config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
            profile = pipeline.start(config)

            # Ïπ¥Î©îÎùº Intrinsics Í∞ÄÏ†∏Ïò§Í∏∞
            color_profile = profile.get_stream(rs.stream.color)
            intr = color_profile.as_video_stream_profile().get_intrinsics()
            fx, fy, cx, cy = intr.fx, intr.fy, intr.ppx, intr.ppy

            # Depth ‚Üí RGB Ï†ïÎ†¨ ÏàòÌñâ
            align_to = rs.stream.color
            align = rs.align(align_to)

            # ÌîÑÎ†àÏûÑ ÏàòÏßë Î∞è Ï†ïÎ†¨
            frames = pipeline.wait_for_frames()
            aligned_frames = align.process(frames)

            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()

            if not depth_frame or not color_frame:
                raise RuntimeError("‚ö†Ô∏è Failed to capture frames from Realsense.")

            # numpy Î∞∞Ïó¥ Î≥ÄÌôò
            depth_map = np.asanyarray(depth_frame.get_data()).astype(np.float32)
            rgb_image = np.asanyarray(color_frame.get_data())

            pipeline.stop()

        except RuntimeError:
            print("No device connected (error during capture), using default intrinsics")
            profile = None
            depth_map = np.zeros((height, width), dtype=np.float32)  # Îπà Depth Îßµ ÏÉùÏÑ±
            rgb_image = np.zeros((height, width, 3), dtype=np.uint8)  # Îπà RGB Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±

    return depth_map, rgb_image

#--------Ï§ëÎ≥µÎ∞ïÏä§ ÏûàÎäîÏßÄ Ï≤¥ÌÅ¨ 
def check_duplicate(results):
    seen = set()
    duplicates = False
    for result in results:
        if hasattr(result, "boxes") and result.boxes is not None:
            for box in result.boxes:
                cls_id = int(box.cls[0])
                if cls_id in seen:
                    duplicates = True
                else:
                    seen.add(cls_id)
    return duplicates # Î∂àÎ¶¨Ïïà ÏïÑÏõÉÌíãÏûÑ

#------- Ï§ëÎ≥µÎ∞ïÏä§ ÏóÜÏï†Í≥† Í∞ÄÍπåÏö¥Í≤ÉÎßå Î∞òÌôò
def remove_extra_box(results, depth_map):
    all_boxes = []  # Î™®Îì† Î∞îÏö¥Îî© Î∞ïÏä§Î•º Ï†ÄÏû•Ìï† Î¶¨Ïä§Ìä∏

    # YOLO ÌÉêÏßÄ Í≤∞Í≥ºÏóêÏÑú Î™®Îì† Î∞îÏö¥Îî© Î∞ïÏä§ ÏàòÏßë (ÌÅ¥ÎûòÏä§ ID Ìè¨Ìï®)
    for result in results:
        for box in result.boxes:
            bbox = tuple(map(int, box.xyxy[0]))  # Î∞îÏö¥Îî© Î∞ïÏä§ Ï¢åÌëú (x1, y1, x2, y2)
            cls_id = int(box.cls[0])  # ÌÅ¥ÎûòÏä§ ID Í∞ÄÏ†∏Ïò§Í∏∞
            all_boxes.append((cls_id, bbox))  # (ÌÅ¥ÎûòÏä§ ID, Î∞îÏö¥Îî© Î∞ïÏä§) Ï†ÄÏû•

    # ÌÉêÏßÄÎêú Í∞ùÏ≤¥Í∞Ä ÏóÜÏúºÎ©¥ (None, None) Î∞òÌôò
    if not all_boxes:
        return (None, None)

    # Í∞ÄÏû• Í∞ÄÍπåÏö¥ Í∞ùÏ≤¥ Ï∞æÍ∏∞
    return get_closest_box_with_depth(all_boxes, depth_map)


def get_closest_box_with_depth(boxes, depth_map):
    """ Í∞ÄÏû• Í∞ÄÍπåÏö¥ Î∞îÏö¥Îî© Î∞ïÏä§Î•º ÏÑ†ÌÉù (ÏµúÏÜå Depth Í∞í Í∏∞Ï§Ä) """
    min_depth = float("inf")
    closest_box = None
    closest_cls_id = None

    for cls_id, bbox in boxes:
        x1, y1, x2, y2 = bbox
        roi_depth = depth_map[y1:y2, x1:x2]  

        # 0Ïù¥ ÏïÑÎãå Depth Í∞íÏù¥ ÏûàÏúºÎ©¥ ÏµúÏÜüÍ∞í Í≥ÑÏÇ∞ 
        valid_depths = roi_depth[roi_depth > 0]
        if len(valid_depths) > 0:
            min_roi_depth = np.min(valid_depths)  
            if min_roi_depth < min_depth:
                min_depth = min_roi_depth
                closest_box = bbox
                closest_cls_id = cls_id  # Í∞ÄÏû• Í∞ÄÍπåÏö¥ Î∞ïÏä§Ïùò ÌÅ¥ÎûòÏä§ ID Ï†ÄÏû•

    return (closest_cls_id, closest_box) 

def extract_plane_ransac(depth_map, intrinsic_matrix=Config.intrinsic_matrix, threshold=0.01):
    """
    Depth Ïù¥ÎØ∏ÏßÄÏóêÏÑú Ïó¨Îü¨ ÌèâÎ©¥ÏùÑ Ï∂îÏ∂úÌïòÍ≥†, Í∞Å ÌèâÎ©¥Ïùò ÏµúÏÜå Depth Í∞íÏùÑ Í≥ÑÏÇ∞ÌïòÏó¨
    Í∞ÄÏû• Í∞ÄÍπåÏö¥ ÌèâÎ©¥ÏùÑ ÏÑ†ÌÉùÌï©ÎãàÎã§.
    :param depth_map: (H, W) ÌòïÌÉúÏùò Depth Ïù¥ÎØ∏ÏßÄ
    :param intrinsic_matrix: Ïπ¥Î©îÎùº ÎÇ¥Ï†Å ÌñâÎ†¨ (fx, fy, cx, cy Ìè¨Ìï®)
    :param threshold: RANSACÏóêÏÑú ÌèâÎ©¥Í≥ºÏùò Í±∞Î¶¨ Í∏∞Ï§Ä
    :return: Í∞ÄÏû• Í∞ÄÍπåÏö¥ ÌèâÎ©¥Ïóê Ìï¥ÎãπÌïòÎäî Ìè¨Ïù∏Ìä∏Îì§ (inliers)
    """
    # Depth Ïù¥ÎØ∏ÏßÄÎ•º Ìè¨Ïù∏Ìä∏ÌÅ¥ÎùºÏö∞ÎìúÎ°ú Î≥ÄÌôò
    pcd = depth_to_pointcloud(depth_map, intrinsic_matrix)
    
    # RANSACÏùÑ Ïù¥Ïö©Ìï¥ Ïó¨Îü¨ ÌèâÎ©¥ Î™®Îç∏ Ï∂îÏ∂ú
    planes = []
    for _ in range(10):  # ÌèâÎ©¥ÏùÑ Ïó¨Îü¨ Í∞ú Ï∂îÏ∂ú (Ïòà: 10Î≤à Î∞òÎ≥µ)
        plane_model, inliers = pcd.segment_plane(distance_threshold=threshold, ransac_n=3, num_iterations=1000)
        inlier_cloud = pcd.select_by_index(inliers)
        planes.append((plane_model, inlier_cloud))
        
        # Ï∂îÏ∂úÎêú ÌèâÎ©¥ÏùÑ Ìè¨Ïù∏Ìä∏ÌÅ¥ÎùºÏö∞ÎìúÏóêÏÑú Ï†úÏô∏ÏãúÏºú Îã§Ïùå ÌèâÎ©¥ÏùÑ Ï∞æÍ∏∞ ÏúÑÌï¥
        pcd = pcd.select_by_index(inliers, invert=True)  
    
    # Í∞Å ÌèâÎ©¥Ïùò Depth Í≥ÑÏÇ∞ (ÌèâÎ©¥Ïóê Ìè¨Ìï®Îêú Ï†êÎì§Ïùò ÏµúÏÜå Depth Í∞í)
    min_depth = float('inf')
    closest_plane = None
    
    for plane_model, inlier_cloud in planes:
        # ÌèâÎ©¥Ïóê Ìè¨Ìï®Îêú Ï†êÎì§Ïùò ÍπäÏù¥ Í∞í Í≥ÑÏÇ∞
        inlier_points = np.asarray(inlier_cloud.points)
        min_plane_depth = np.min(inlier_points[:, 2])  # Z Í∞íÏù¥ DepthÏóê Ìï¥Îãπ
        
        # Í∞ÄÏû• ÏûëÏùÄ Depth Í∞íÏùÑ Í∞ÄÏßÑ ÌèâÎ©¥ÏùÑ ÏÑ†ÌÉù
        if min_plane_depth < min_depth:
            min_depth = min_plane_depth
            closest_plane = inlier_cloud
    
    return closest_plane






#-----------Î∞îÏö¥Îî©Î∞ïÏä§Ïùò ROI ÌÅ¨Î°≠ÌïòÍ∏∞
def crop_roi(bbox, rgb_image, depth_map):
    x1,y1,x2,y2 = bbox
    rgb_roi = rgb_image[y1:y2, x1:x2, :]
    depth_roi = depth_map[y1:y2, x1:x2]
    return rgb_roi, depth_roi


#--------- ÌÅ¥ÎûòÏä§ Î∂ÑÎ•òÌï¥ÏÑú Ìï®Ïàò Ïã§Ìñâ ‚ùó‚ùó‚ùó‚ùó‚ùó‚ùó‚ùó‚ùó‚ùó‚ùóÏàòÏ†ïÌïÑÏöî
def measure_height(cls_id,rgb_roi, depth_roi, model):
    if cls_id ==0:
        angle, height = stairs.measure_height(depth_roi)
    #‚ùóÎîîÎ≤ÑÍπÖÏö©
    print("ÎÜíÏù¥ Ï∏°Ï†ïÏ§ë")
    return angle, height









# ----------------------
# Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú
# ----------------------
if __name__ == "__main__":
    # Í∞ÄÏ†ï: color_img (BGR)ÏôÄ YOLOÎ°úÎ∂ÄÌÑ∞ ÏñªÏùÄ bbox, ÏÑ∏Í∑∏Î©òÌÖåÏù¥ÏÖò Î™®Îç∏ Ï§ÄÎπÑ
    color_img = cv2.imread("test.jpg")
    yolo_bbox = (100, 200, 400, 500)  # ÏòàÏãú (x1, y1, x2, y2)

    # Ïòà: ÏûÑÏùòÏùò ÏÑ∏Í∑∏Î©òÌÖåÏù¥ÏÖò Î™®Îç∏ (PyTorch)
    # model = MySegModel(...)
    # model.load_state_dict(torch.load("model.pth"))
    # device = 'cuda' if torch.cuda.is_available() else 'cpu'
    # model.to(device)

    # Ïó¨Í∏∞ÏÑúÎäî Îç∞Î™®ÎùºÏÑú model ÎåÄÏã† None Ï≤òÎ¶¨
    model = None
    device = 'cpu'

    # ÏÑ∏Í∑∏Î©òÌÖåÏù¥ÏÖò Ìï®Ïàò ÏãúÏó∞ (Ïã§Ï†úÎ°úÎäî modelÏù¥ ÌïÑÏöî)
    # segment_stairs_in_roi Ìï®Ïàò ÎÇ¥ model Î∂ÄÎ∂ÑÏùÑ ÏßÅÏ†ë ÏàòÏ†ïÌï¥ÏÑú ÏÇ¨Ïö© Í∞ÄÎä•
    # ÌòπÏùÄ ÏïÑÎûòÏ≤òÎüº "ÎçîÎØ∏"Î°ú ÏòàÏãúÎ•º ÎßåÎì§ ÏàòÎèÑ ÏûàÏùå
    def dummy_model(x):
        # ÏûÖÎ†• x: (1,3,h,w)
        # Í∞ÄÏßúÎ°ú Ï†ÑÎ∂Ä '1' ÌÅ¥ÎûòÏä§ÎùºÍ≥† ÏπòÏûê (Ï†ÑÎ∂Ä Í≥ÑÎã®)
        return torch.zeros((1, 2, x.shape[2], x.shape[3]), device=x.device) + 0.5

    seg_model = dummy_model

    mask_roi = stairs.segment_stairs_in_roi(color_img, yolo_bbox, seg_model, device=device)
    
    # ÌõÑÏÜçÏ≤òÎ¶¨
    edges, lines_p = stairs.postprocess_stair_mask(mask_roi)

    # ÏãúÍ∞ÅÌôî ÏòàÏãú
    # ROI ÏòÅÏó≠Îßå ÏãúÍ∞ÅÌôî
    x1, y1, x2, y2 = yolo_bbox
    roi_vis = color_img[y1:y2, x1:x2].copy()

    # ÏóêÏßÄ Í∑∏Î¶¨Í∏∞
    edges_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    edges_bgr[edges != 0] = (0, 0, 255)  # Îπ®Í∞ÑÏÉâ

    # lines_pÍ∞Ä ÏûàÏúºÎ©¥ ÏßÅÏÑ† ÏãúÍ∞ÅÌôî
    if lines_p is not None:
        for line in lines_p:
            x_start, y_start, x_end, y_end = line[0]
            cv2.line(roi_vis, (x_start, y_start), (x_end, y_end), (0,255,0), 2)

    # Í≤∞Í≥º Î≥¥Í∏∞
    cv2.imshow("ROI mask", mask_roi*255)  # 0 or 1 => ÏãúÍ∞ÅÌôîÎ•º ÏúÑÌï¥ 255 Í≥±
    cv2.imshow("ROI edges", edges_bgr)
    cv2.imshow("ROI lines", roi_vis)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
